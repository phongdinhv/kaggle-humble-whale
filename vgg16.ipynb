{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VuDinhPhong\\Anaconda3\\envs\\YOLO-env\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "import sklearn\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_IMG_FOLDER = os.path.join(os.getcwd(), 'train')\n",
    "\n",
    "RESIZE_WIDTH = 178\n",
    "RESIZE_HEIGH = 178\n",
    "\n",
    "INPUT_WIDTH = 178\n",
    "INPUT_HEIGHT = 178\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 100\n",
    "\n",
    "FIG_SIZE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00022e1a.jpg</td>\n",
       "      <td>w_e15442c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>w_1287fbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00087b01.jpg</td>\n",
       "      <td>w_da2efe0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001296d5.jpg</td>\n",
       "      <td>w_19e5482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014cfdf.jpg</td>\n",
       "      <td>w_f22f3e3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image         Id\n",
       "0  00022e1a.jpg  w_e15442c\n",
       "1  000466c4.jpg  w_1287fbc\n",
       "2  00087b01.jpg  w_da2efe0\n",
       "3  001296d5.jpg  w_19e5482\n",
       "4  0014cfdf.jpg  w_f22f3e3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('train.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs_from_folder(folder, filenames=None):\n",
    "    \"\"\"\n",
    "        Read images into a numpy array\n",
    "        Input: \n",
    "            - folder: a path\n",
    "            - filenames: list of images name in folder \n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    file_names = filenames if filenames is not None else train_csv.Image\n",
    "    for f in file_names:\n",
    "        img = cv2.imread(os.path.join(folder, f))\n",
    "        img = cv2.resize(img, (RESIZE_WIDTH, RESIZE_HEIGH))\n",
    "        img = img.reshape(1, RESIZE_WIDTH, RESIZE_HEIGH, 3)\n",
    "        imgs.append(img)\n",
    "    imgs = np.vstack(imgs)\n",
    "    return imgs\n",
    "\n",
    "def load_data_from_file(hdf5_file):\n",
    "    \"\"\"\n",
    "        Load numpy array from hdf5\n",
    "        \n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imgs(imgs_list, imgs_name=None):\n",
    "    \n",
    "    fig = plt.figure(figsize=(FIG_SIZE,FIG_SIZE))\n",
    "    if imgs_name is None:\n",
    "        imgs_name = np.arange(len(imgs_list))\n",
    "        \n",
    "    _COL = 5\n",
    "    _ROW = (len(imgs_list)/_COL) + 1\n",
    "    \n",
    "    if not isinstance(imgs_list, list):\n",
    "        imgs_list = [imgs_list]\n",
    "    \n",
    "    for i,im in enumerate(imgs_list):\n",
    "        \n",
    "        ax = fig.add_subplot(_ROW, _COL, i+1)\n",
    "        \n",
    "        ax.set_title(imgs_name[i])\n",
    "        ax.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelOntHotEncoder():\n",
    "    \"\"\"\n",
    "         A class which transform labels data to ont hot encoding\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Y):\n",
    "        \"\"\"\n",
    "            Initialize with training label Y\n",
    "        \"\"\"\n",
    "        if not any(Y):\n",
    "            raise ValueError('Intialize error, missing Y')\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_binarizer = LabelBinarizer()\n",
    "        self.Y_encoded = self.label_encoder.fit_transform(Y)\n",
    "        self.y_one_hot = self.label_binarizer.fit_transform(self.Y_encoded)\n",
    "    \n",
    "    def Y_one_hot(self):\n",
    "        return self.y_one_hot\n",
    "    \n",
    "    def encode(self, y):\n",
    "        \"\"\"\n",
    "            Input y: array of shape (N, ) contains category of class like 'new_whale', ...\n",
    "            return: One hot like (N, num_class)\n",
    "        \"\"\"\n",
    "        y_encoded = self.label_encoder.transform(y)\n",
    "        return self.label_binarizer.transform(y_encoded)\n",
    "    \n",
    "    def decode(self, y):\n",
    "        \"\"\"\n",
    "            Input y: numpy array of shape (N, num_class) contains ont not like [ [0,1,0,0,...], [1,0,0,0,...] ]\n",
    "            return: numpy array of string classes\n",
    "        \"\"\"\n",
    "        y_decoded = self.label_binarizer.inverse_transform(y)\n",
    "        return self.label_encoder.inverse_transform(y_decoded)\n",
    "    \n",
    "    def num_class(self):\n",
    "        \n",
    "        return len(self.label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9850, 178, 178, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = load_imgs_from_folder(TRAINING_IMG_FOLDER, train_csv.Image)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9850, 4251)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelOntHotEncoder(train_csv.Id.values)\n",
    "y_one_hot = label_encoder.Y_one_hot()\n",
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(featurewise_center=True,  \n",
    "                                   featurewise_std_normalization=True, \n",
    "                                   rotation_range=20, rescale=1./255, \n",
    "                                   zoom_range=0.2, \n",
    "                                   validation_split = 0.2)\n",
    "train_datagen.fit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_intermediate_layer_in_keras(model, layer_id, new_layer):\n",
    "    from keras.models import Model\n",
    "\n",
    "    layers = [l for l in model.layers]\n",
    "\n",
    "    x = layers[0].output\n",
    "    for i in range(1, len(layers)):\n",
    "        if i == layer_id:\n",
    "            x = new_layer(axis=-1)(x)\n",
    "        x = layers[i](x)\n",
    "\n",
    "    new_model = Model(inputs=layers[0].input, outputs=x)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 178, 178, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 178, 178, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 178, 178, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 178, 178, 64)      256       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 89, 89, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 89, 89, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 89, 89, 128)       512       \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 89, 89, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 44, 44, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 44, 44, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 44, 44, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 44, 44, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 44, 44, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 22, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 22, 22, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              52432896  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4251)              17416347  \n",
      "=================================================================\n",
      "Total params: 101,350,107\n",
      "Trainable params: 101,347,675\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_net = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(INPUT_WIDTH,INPUT_HEIGHT,3))\n",
    "\n",
    "# Adding fully-connected at the end\n",
    "flatten = Flatten()(vgg_net.output)\n",
    "fully = Dense(4096, activation='relu')(flatten)\n",
    "fully = Dense(4096, activation='relu')(fully)\n",
    "preds = Dense(label_encoder.num_class(), activation='softmax')(fully)\n",
    "vgg_net = Model(vgg_net.input, preds)\n",
    "\n",
    "# Adding BatchNorm\n",
    "vgg_net = insert_intermediate_layer_in_keras(vgg_net, 3, BatchNormalization)\n",
    "vgg_net = insert_intermediate_layer_in_keras(vgg_net, 6, BatchNormalization)\n",
    "vgg_net = insert_intermediate_layer_in_keras(vgg_net, 10, BatchNormalization)\n",
    "vgg_net = insert_intermediate_layer_in_keras(vgg_net, 14, BatchNormalization)\n",
    "vgg_net = insert_intermediate_layer_in_keras(vgg_net, 18, BatchNormalization)\n",
    "\n",
    "\n",
    "vgg_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_categorical_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_net.compile(optimizer=Adam(), \n",
    "                loss=categorical_crossentropy, \n",
    "                metrics=[top_5_categorical_accuracy], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "308/307 [==============================] - 119s 386ms/step - loss: 8.1496 - top_5_categorical_accuracy: 0.0882\n",
      "Epoch 2/100\n",
      "308/307 [==============================] - 113s 365ms/step - loss: 7.7881 - top_5_categorical_accuracy: 0.0925\n",
      "Epoch 3/100\n",
      "308/307 [==============================] - 113s 366ms/step - loss: 7.7428 - top_5_categorical_accuracy: 0.0922\n",
      "Epoch 4/100\n",
      "308/307 [==============================] - 112s 363ms/step - loss: 7.7314 - top_5_categorical_accuracy: 0.0926\n",
      "Epoch 5/100\n",
      "308/307 [==============================] - 113s 366ms/step - loss: 7.7257 - top_5_categorical_accuracy: 0.0923\n",
      "Epoch 6/100\n",
      "308/307 [==============================] - 112s 363ms/step - loss: 7.7227 - top_5_categorical_accuracy: 0.0927\n",
      "Epoch 7/100\n",
      "308/307 [==============================] - 111s 361ms/step - loss: 7.7210 - top_5_categorical_accuracy: 0.0928\n",
      "Epoch 8/100\n",
      "308/307 [==============================] - 112s 364ms/step - loss: 7.7183 - top_5_categorical_accuracy: 0.0925\n",
      "Epoch 9/100\n",
      "308/307 [==============================] - 112s 363ms/step - loss: 7.7188 - top_5_categorical_accuracy: 0.0930\n",
      "Epoch 10/100\n",
      "308/307 [==============================] - 112s 364ms/step - loss: 7.7166 - top_5_categorical_accuracy: 0.0926\n",
      "Epoch 11/100\n",
      "308/307 [==============================] - 113s 367ms/step - loss: 7.7153 - top_5_categorical_accuracy: 0.0926\n",
      "Epoch 12/100\n",
      " 57/307 [====>.........................] - ETA: 1:31 - loss: 7.6622 - top_5_categorical_accuracy: 0.0948"
     ]
    }
   ],
   "source": [
    "vgg_net.fit_generator(generator=train_datagen.flow(x, y_one_hot, batch_size=BATCH_SIZE),\n",
    "                      steps_per_epoch=x.shape[0]/BATCH_SIZE, epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
